{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.json import loads, json_normalize\n",
    "\n",
    "# challenge specifies to load fullVisitorId as a string to guarantee uniqueness\n",
    "id_to_str = {'fullVisitorId': str}\n",
    "\n",
    "train = pd.read_csv('./all/train.csv', nrows=100000, dtype=id_to_str)\n",
    "test  = pd.read_csv('./all/test.csv', nrows=1, dtype=id_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_cols(df):\n",
    "    for col in ['device', 'geoNetwork', 'totals', 'trafficSource']:\n",
    "        # load the json and separate\n",
    "        df_json = json_normalize(df[col].apply(loads), sep='/')\n",
    "        df_json.columns = [(col + '/' + c) for c in df_json.columns]\n",
    "        df.drop(columns=col, inplace=True)\n",
    "        df = pd.concat([df, df_json], axis=1)\n",
    "    return df\n",
    "\n",
    "#\n",
    "train = parse_json_cols(train)\n",
    "test  = parse_json_cols(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Examine data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates are not parsed and visitStartTime is in POSIX time\n",
    "    * visitStartTime makes Date redundant (more information encoded)\n",
    "    * need to get continuous time data (hour, minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def parse_dates(df):\n",
    "    df['visitStartTime'] = df['visitStartTime'].apply(lambda time: datetime.fromtimestamp(time))\n",
    "    df['year']  = df['visitStartTime'].dt.year\n",
    "    df['month'] = df['visitStartTime'].dt.month\n",
    "    df['day']   = df['visitStartTime'].dt.day\n",
    "    df['hour']  = df['visitStartTime'].dt.hour + (df['visitStartTime'].dt.minute/60)\n",
    "    df.drop(columns=['date', 'visitStartTime'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "#\n",
    "train = parse_dates(train)\n",
    "test  = parse_dates(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Several columns have NaN values\n",
    "* Every value in totals should have a lower bound of 0.\n",
    "* Will fill remainder with most frequent value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "totals/bounces                                  True\n",
       "totals/newVisits                                True\n",
       "totals/pageviews                                True\n",
       "totals/transactionRevenue                       True\n",
       "trafficSource/adContent                         True\n",
       "trafficSource/adwordsClickInfo/adNetworkType    True\n",
       "trafficSource/adwordsClickInfo/gclId            True\n",
       "trafficSource/adwordsClickInfo/isVideoAd        True\n",
       "trafficSource/adwordsClickInfo/page             True\n",
       "trafficSource/adwordsClickInfo/slot             True\n",
       "trafficSource/campaignCode                      True\n",
       "trafficSource/isTrueDirect                      True\n",
       "trafficSource/keyword                           True\n",
       "trafficSource/referralPath                      True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_series = train.isna().any()\n",
    "nan_true   = nan_series[nan_series == True]\n",
    "nan_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nans(df):\n",
    "    totals_cols = list(filter(lambda c : c.startswith('totals'), df.columns))\n",
    "    for i in totals_cols:\n",
    "        df[i] = df[i].astype(float)\n",
    "        df[i].fillna(0, inplace=True)\n",
    "   \n",
    "    nan_series = df.isna().any()\n",
    "    nan_true   = nan_series[nan_series == True]\n",
    "    remaining_nan_cols = list(set(nan_true.index) - set(totals_cols))\n",
    "    \n",
    "    for i in remaining_nan_cols:\n",
    "        # fill with most frequent value\n",
    "        df[i].fillna(df[i].value_counts().index[0], inplace=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "#\n",
    "train = clean_nans(train)\n",
    "test  = clean_nans(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Several columns have 1 unique value\n",
    "    * Provide no information, so will drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "socialEngagementType\n",
      "device/browserSize\n",
      "device/browserVersion\n",
      "device/flashVersion\n",
      "device/language\n",
      "device/mobileDeviceBranding\n",
      "device/mobileDeviceInfo\n",
      "device/mobileDeviceMarketingName\n",
      "device/mobileDeviceModel\n",
      "device/mobileInputSelector\n",
      "device/operatingSystemVersion\n",
      "device/screenColors\n",
      "device/screenResolution\n",
      "geoNetwork/cityId\n",
      "geoNetwork/latitude\n",
      "geoNetwork/longitude\n",
      "geoNetwork/networkLocation\n",
      "totals/visits\n",
      "trafficSource/adwordsClickInfo/criteriaParameters\n",
      "trafficSource/adwordsClickInfo/isVideoAd\n",
      "trafficSource/campaignCode\n",
      "trafficSource/isTrueDirect\n"
     ]
    }
   ],
   "source": [
    "for col in train:\n",
    "    if len(train[col].unique()) == 1:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_single_val_cols(df):\n",
    "    for col in df:\n",
    "        if len(df[col].unique()) == 1:\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "    return df\n",
    "\n",
    "#\n",
    "train = drop_single_val_cols(train)\n",
    "test  = drop_single_val_cols(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A lot of data is categorical\n",
    "* Thinks like referal links, locations, and keywords are categorical and need to be represented as such\n",
    "    * Create features depending on importance of certain values\n",
    "    * Dropping certain columns with seemingly redundant or unnecessary data\n",
    "    * Will use one-hot encoding for the rest, bucketing less frequent values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['channelGrouping',\n",
       " 'sessionId',\n",
       " 'device/browser',\n",
       " 'device/deviceCategory',\n",
       " 'device/operatingSystem',\n",
       " 'geoNetwork/city',\n",
       " 'geoNetwork/continent',\n",
       " 'geoNetwork/country',\n",
       " 'geoNetwork/metro',\n",
       " 'geoNetwork/networkDomain',\n",
       " 'geoNetwork/region',\n",
       " 'geoNetwork/subContinent',\n",
       " 'trafficSource/adContent',\n",
       " 'trafficSource/adwordsClickInfo/adNetworkType',\n",
       " 'trafficSource/adwordsClickInfo/gclId',\n",
       " 'trafficSource/adwordsClickInfo/page',\n",
       " 'trafficSource/adwordsClickInfo/slot',\n",
       " 'trafficSource/campaign',\n",
       " 'trafficSource/keyword',\n",
       " 'trafficSource/medium',\n",
       " 'trafficSource/referralPath',\n",
       " 'trafficSource/source']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep an unencoded copy for visualization\n",
    "unencoded_train = train.copy(deep=True)\n",
    "\n",
    "categories = list(train.select_dtypes(include='object').columns)\n",
    "categories.remove('fullVisitorId')\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: Contains \"Google\"\n",
    "* For the following columns, many rows with non-zero revenue have a string containing some variation of \"Google\"\n",
    "    * trafficSource/keyword\n",
    "    * trafficSource/adContent\n",
    "    * trafficSource/adwordsClickInfo/adNetworkType\n",
    "    * trafficSource/source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "google_cols = ['trafficSource/keyword', \n",
    "               'trafficSource/adContent', \n",
    "               'trafficSource/adwordsClickInfo/adNetworkType', \n",
    "               'trafficSource/source']\n",
    "\n",
    "def contains_google(df):\n",
    "    for i in google_cols:\n",
    "        if i not in df.columns:\n",
    "            continue\n",
    "        df['{0}/contains_google'.format(i)] =\\\n",
    "        df[i].apply(lambda x: bool(re.search('google', x, re.IGNORECASE)))\n",
    "        df.drop(columns=[i], inplace=True)\n",
    "    return df\n",
    "\n",
    "#\n",
    "train = contains_google(train)\n",
    "test  = contains_google(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Removing some columns for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['sessionId',\n",
    "           'trafficSource/adwordsClickInfo/gclId',\n",
    "           'trafficSource/adwordsClickInfo/page',\n",
    "           'trafficSource/campaign',\n",
    "           'trafficSource/referralPath']\n",
    "\n",
    "def drop_columns(df):\n",
    "    for c in to_drop:\n",
    "        if c in df.columns:\n",
    "            df.drop(columns=[c], inplace=True)\n",
    "    return df\n",
    "        \n",
    "#\n",
    "train = drop_columns(train)\n",
    "test  = drop_columns(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(train.select_dtypes(include='object').columns)\n",
    "categories.remove('fullVisitorId')\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(df):\n",
    "    for i in categories:\n",
    "        print(i)\n",
    "        if i not in df.columns:\n",
    "            continue\n",
    "        value_counts = df[i].value_counts()\n",
    "        if len(value_counts) > 4:\n",
    "            bound = value_counts[3]\n",
    "            print(bound)\n",
    "            bucket = value_counts[value_counts <= bound].index\n",
    "            print(len(bucket), 'in bucket')\n",
    "            if len(bucket) >= 1:\n",
    "                df[i] = df[i].replace(bucket, 'bucket')\n",
    "        print(len(df[i].value_counts()))\n",
    "    df = pd.get_dummies(df, columns=categories)\n",
    "    return df\n",
    "\n",
    "#\n",
    "train = one_hot(train)\n",
    "test  = one_hot(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict natural log of revenue\n",
    "* Target specified as ln(total transaction revenue + 1)\n",
    "    * Need to convert transactionRevenue column to accomodate\n",
    "* Evaluate with RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import log1p\n",
    "\n",
    "# to make the line more readable\n",
    "i = 'totals/transactionRevenue'\n",
    "\n",
    "train[i] = train[i].apply(lambda revenue: log1p(revenue))\n",
    "unencoded_train[i] = unencoded_train[i].apply(lambda revenue: log1p(revenue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External Dataset: OECD Consumer Confidence Index\n",
    "\n",
    "OECD - Total from Jan 2016 - Sep 2018\n",
    "\n",
    "https://data.oecd.org/leadind/consumer-confidence-index-cci.htm#indicator-chart\n",
    "\n",
    "\n",
    "* OECD (2018), Consumer confidence index (CCI) (indicator). doi: 10.1787/46434d78-en (Accessed on 11 October 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cci(df):\n",
    "    cci = pd.read_csv('./all/oecd_total_cci.csv', index_col=0)\n",
    "    cci_dict = cci.to_dict()['Value']\n",
    "    df['year-month']  = df['year'].astype(str) + '-' + df['month'].astype(str)\n",
    "    \n",
    "    df['cci'] = df['year-month'].map(cci_dict)\n",
    "    df['cci'].fillna(df['cci'].median(), inplace=True)\n",
    "    \n",
    "    df.drop(columns=['year-month'], inplace=True)\n",
    "    return df\n",
    "\n",
    "train = add_cci(train)\n",
    "test  = add_cci(test)\n",
    "unencoded_train = add_cci(unencoded_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Preprocessed DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.to_csv('./all/p_train.csv', index=False)\n",
    "#test.to_csv('./all/p_test.csv', index=False)\n",
    "#unencoded_train.to_csv('./all/unencoded_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "# Load Preprocessed DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "id_to_str = {'fullVisitorId': str}\n",
    "\n",
    "#train = pd.read_csv('./all/p_train.csv', dtype=id_to_str)\n",
    "#test  = pd.read_csv('./all/p_test.csv', dtype=id_to_str)\n",
    "unencoded_train = pd.read_csv('./all/unencoded_train.csv', dtype=id_to_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unencoded_train['trafficSource/adwordsClickInfo/page'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cats = unencoded_train.select_dtypes(exclude='object')\n",
    "\n",
    "i = 'totals/transactionRevenue'\n",
    "columns = list(no_cats.columns)\n",
    "columns.remove(i); columns.append(i)\n",
    "\n",
    "no_cats = no_cats[columns]\n",
    "\n",
    "no_cats_corr = no_cats.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Correlation Matrix (Non-Categorical Variables)', fontsize=15)\n",
    "sns.heatmap(no_cats_corr, cmap='coolwarm', annot=True, vmin=-1, vmax=1, \n",
    "            cbar_kws=dict(ticks=list(np.arange(-1.0, 1.1, 0.25))), fmt='.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cats.corr()['totals/transactionRevenue'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### The majority of paying customers will view the site under 30 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_tr = train[train['totals/transactionRevenue'] > 0]\n",
    "p_99 = np.percentile(pv_tr['totals/pageviews'].sort_values(), 99)\n",
    "pv_tr = pv_tr[pv_tr['totals/pageviews'] < p_99]\n",
    "\n",
    "x_values = pv_tr['totals/pageviews']\n",
    "y_values = pv_tr['totals/transactionRevenue']\n",
    "\n",
    "xy = np.vstack([x_values, y_values]); \n",
    "density = gaussian_kde(xy)(xy)\n",
    "\n",
    "plt.figure(figsize=(12, 10)); plt.title('Page Views of Paying Customers', fontsize=20)\n",
    "plt.xticks(np.arange(0, x_values.max(), step=5)); plt.yticks(np.arange(0, y_values.max(), step=1))\n",
    "plt.xlabel('Page Views', fontsize=15); plt.ylabel('Log Transaction Revenue', fontsize=15)\n",
    "plt.scatter(x_values, y_values, alpha=1, c=density, cmap='jet')\n",
    "#plt.colorbar(ticks=[], aspect=50).set_label('Relative Density', fontsize=20)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Referalls bring in the most page views and the most revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser_rev = unencoded_train[['totals/transactionRevenue', 'channelGrouping']]\n",
    "#browser_rev = browser_rev[browser_rev['totals/transactionRevenue'] > 0]\n",
    "browser_rev = browser_rev.groupby('channelGrouping').mean()\n",
    "browser_rev = browser_rev.sort_values(by='totals/transactionRevenue', ascending=False)\n",
    "x = browser_rev.index\n",
    "y = browser_rev['totals/transactionRevenue']\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x, y).set_title('A')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_revenue = train[['totals/transactionRevenue', 'device/isMobile']]\n",
    "mobile_revenue = mobile_revenue.groupby('device/isMobile').sum()\n",
    "x = mobile_revenue.index\n",
    "y = mobile_revenue['totals/transactionRevenue']\n",
    "sns.barplot(x, y).set_title('A')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unencoded_train['month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unencoded_train['channelGrouping'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "https://support.google.com/analytics/answer/3297892?hl=en&ref_topic=6010089"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = unencoded_train[['channelGrouping', 'totals/transactionRevenue', 'month']]\n",
    "\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.xticks(np.arange(0, 12+1, step=1))\n",
    "channels = channels.sort_values(by='month')\n",
    "\n",
    "sns.set(style=\"ticks\", rc={\"lines.linewidth\": 6})\n",
    "sns.lineplot('month', 'totals/transactionRevenue', data=channels, err_style=None, estimator='mean', palette=\"colorblind\",  hue='channelGrouping')\n",
    "plt.title('Mean Revenue By Month', fontsize=25)\n",
    "plt.xlabel('Month', fontsize=20); \n",
    "plt.ylabel('Log Transaction Revenue', fontsize=20)\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=1, frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = unencoded_train[['channelGrouping', 'totals/pageviews', 'month']]\n",
    "channels = channels[channels['channelGrouping'] != '(Other)']\n",
    "\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.xticks(np.arange(0, 12+1, step=1))\n",
    "channels = channels.sort_values(by='month')\n",
    "\n",
    "sns.set(style=\"ticks\", rc={\"lines.linewidth\": 6})\n",
    "sns.lineplot('month', 'totals/pageviews', data=channels, err_style=None,  hue='channelGrouping')\n",
    "plt.title('Page Views By Month and Channel Grouping', fontsize=20)\n",
    "plt.xlabel('Month', fontsize=15); \n",
    "plt.ylabel('Page Views', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tt_split(df):\n",
    "    X = df.drop(columns=['totals/transactionRevenue', 'fullVisitorId'])\n",
    "    y = df['totals/transactionRevenue']\n",
    "    \n",
    "    return train_test_split(X, y, test_size = 0.1, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt\n",
    "from numpy import clip\n",
    "\n",
    "def train_lr(df):\n",
    "    X_train, X_test, y_train, y_test = get_tt_split(df)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    print('Training model: {0}...\\n'.format('lr'))\n",
    "    model.fit(X_train, y_train)\n",
    "    test_predictions = model.predict(X_test)\n",
    "    test_predictions = clip(test_predictions, a_min=0, a_max=None)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, test_predictions)\n",
    "    rmse = sqrt(mse)\n",
    "    \n",
    "    print('=====')\n",
    "    print('RMSE:', rmse)\n",
    "    print('=====\\n\\n==========')\n",
    "    print('INTERCEPT:', model.intercept_)\n",
    "    print('==========\\n\\n==========================')\n",
    "    print('COEFFICIENTS (decreasing):')\n",
    "    print('==========================')\n",
    "    coefficients = list(zip(X_test.columns, model.coef_))\n",
    "    coefficients.sort(key = lambda c: c[1])\n",
    "    for i in coefficients[::-1]:\n",
    "        print('{0}:\\n\\t{1}\\n'.format(i[0], i[1]))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = train_lr(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import DMatrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt\n",
    "from numpy import clip\n",
    "\n",
    "def train_xgb(df):\n",
    "    X_train, X_test, y_train, y_test = get_tt_split(df)\n",
    "    \n",
    "    print('Training model: {0}...'.format('xgb'))\n",
    "    model = xgb.train({'eta':0.6}, DMatrix(X_train, y_train))\n",
    "    test_predictions = model.predict(DMatrix(X_test))\n",
    "    test_predictions = clip(test_predictions, a_min=0, a_max=None)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, test_predictions)\n",
    "    rmse = sqrt(mse)\n",
    "    \n",
    "    print('=====')\n",
    "    print('RMSE:', rmse)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = train_xgb(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Specify model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = 'xgb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(columns=['fullVisitorId'])\n",
    "\n",
    "if selected_model == 'lr':\n",
    "    model = train_lr(train)\n",
    "elif selected_model == 'xgb':\n",
    "    model = train_xgb(train)\n",
    "    X_test = DMatrix(X_test)\n",
    "\n",
    "real_predictions = model.predict(X_test)\n",
    "real_predictions = clip(real_predictions, a_min=0, a_max=None)\n",
    "\n",
    "real_df = test['fullVisitorId'].to_frame()\n",
    "real_df['PredictedLogRevenue'] = real_predictions\n",
    "real_df['fullVisitorId'] = real_df['fullVisitorId'].astype('str')\n",
    "real_df = real_df.groupby('fullVisitorId').sum()\n",
    "real_df.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
