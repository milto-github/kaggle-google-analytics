{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.json import loads, json_normalize\n",
    "\n",
    "# challenge specifies to load fullVisitorId as a string to guarantee uniqueness\n",
    "id_to_str = {'fullVisitorId': str}\n",
    "\n",
    "train = pd.read_csv('./all/train.csv', dtype=id_to_str)\n",
    "test  = pd.read_csv('./all/test.csv', dtype=id_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_cols(df):\n",
    "    for col in ['device', 'geoNetwork', 'totals', 'trafficSource']:\n",
    "        # load the json and separate\n",
    "        df_json = json_normalize(df[col].apply(loads), sep='/')\n",
    "        df_json.columns = [(col + '/' + c) for c in df_json.columns]\n",
    "        df.drop(columns=col, inplace=True)\n",
    "        df = pd.concat([df, df_json], axis=1)\n",
    "    return df\n",
    "\n",
    "#\n",
    "train = parse_json_cols(train)\n",
    "test  = parse_json_cols(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Examine data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates are not parsed and visitStartTime is in POSIX time\n",
    "    * visitStartTime makes Date redundant (more information encoded)\n",
    "    * need to get continuous time data (hour, minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def parse_dates(df):\n",
    "    df['visitStartTime'] = df['visitStartTime'].apply(lambda time: datetime.fromtimestamp(time))\n",
    "    df['year']  = df['visitStartTime'].dt.year\n",
    "    df['month'] = df['visitStartTime'].dt.month\n",
    "    df['day']   = df['visitStartTime'].dt.day\n",
    "    df['hour']  = df['visitStartTime'].dt.hour + (df['visitStartTime'].dt.minute/60)\n",
    "    df.drop(columns=['date', 'visitStartTime'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "#\n",
    "train = parse_dates(train)\n",
    "test  = parse_dates(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Several columns have NaN values\n",
    "* Every value in totals should have a lower bound of 0.\n",
    "* Will fill remainder with most frequent value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "totals/bounces                                  True\n",
       "totals/newVisits                                True\n",
       "totals/pageviews                                True\n",
       "totals/transactionRevenue                       True\n",
       "trafficSource/adContent                         True\n",
       "trafficSource/adwordsClickInfo/adNetworkType    True\n",
       "trafficSource/adwordsClickInfo/gclId            True\n",
       "trafficSource/adwordsClickInfo/isVideoAd        True\n",
       "trafficSource/adwordsClickInfo/page             True\n",
       "trafficSource/adwordsClickInfo/slot             True\n",
       "trafficSource/campaignCode                      True\n",
       "trafficSource/isTrueDirect                      True\n",
       "trafficSource/keyword                           True\n",
       "trafficSource/referralPath                      True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_series = train.isna().any()\n",
    "nan_true   = nan_series[nan_series == True]\n",
    "nan_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nans(df):\n",
    "    totals_cols = list(filter(lambda c : c.startswith('totals'), df.columns))\n",
    "    for i in totals_cols:\n",
    "        df[i] = df[i].astype(float)\n",
    "        df[i].fillna(0, inplace=True)\n",
    "   \n",
    "    nan_series = df.isna().any()\n",
    "    nan_true   = nan_series[nan_series == True]\n",
    "    remaining_nan_cols = list(set(nan_true.index) - set(totals_cols))\n",
    "    \n",
    "    for i in remaining_nan_cols:\n",
    "        # fill with most frequent value\n",
    "        df[i].fillna(df[i].value_counts().index[0], inplace=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "#\n",
    "train = clean_nans(train)\n",
    "test  = clean_nans(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Several columns have 1 unique value\n",
    "    * Provide no information, so will drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "socialEngagementType\n",
      "device/browserSize\n",
      "device/browserVersion\n",
      "device/flashVersion\n",
      "device/language\n",
      "device/mobileDeviceBranding\n",
      "device/mobileDeviceInfo\n",
      "device/mobileDeviceMarketingName\n",
      "device/mobileDeviceModel\n",
      "device/mobileInputSelector\n",
      "device/operatingSystemVersion\n",
      "device/screenColors\n",
      "device/screenResolution\n",
      "geoNetwork/cityId\n",
      "geoNetwork/latitude\n",
      "geoNetwork/longitude\n",
      "geoNetwork/networkLocation\n",
      "totals/visits\n",
      "trafficSource/adwordsClickInfo/criteriaParameters\n",
      "trafficSource/adwordsClickInfo/isVideoAd\n",
      "trafficSource/campaignCode\n",
      "trafficSource/isTrueDirect\n"
     ]
    }
   ],
   "source": [
    "for col in train:\n",
    "    if len(train[col].unique()) == 1:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_single_val_cols(df):\n",
    "    for col in df:\n",
    "        if len(df[col].unique()) == 1:\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "    return df\n",
    "\n",
    "#\n",
    "train = drop_single_val_cols(train)\n",
    "test  = drop_single_val_cols(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A lot of data is categorical\n",
    "* Thinks like referal links, locations, and keywords are categorical and need to be represented as such\n",
    "    * Create features depending on importance of certain values\n",
    "    * Dropping certain columns with seemingly redundant or unnecessary data\n",
    "    * Will use one-hot encoding for the rest, bucketing less frequent values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['channelGrouping',\n",
       " 'sessionId',\n",
       " 'device/browser',\n",
       " 'device/deviceCategory',\n",
       " 'device/operatingSystem',\n",
       " 'geoNetwork/city',\n",
       " 'geoNetwork/continent',\n",
       " 'geoNetwork/country',\n",
       " 'geoNetwork/metro',\n",
       " 'geoNetwork/networkDomain',\n",
       " 'geoNetwork/region',\n",
       " 'geoNetwork/subContinent',\n",
       " 'trafficSource/adContent',\n",
       " 'trafficSource/adwordsClickInfo/adNetworkType',\n",
       " 'trafficSource/adwordsClickInfo/gclId',\n",
       " 'trafficSource/adwordsClickInfo/page',\n",
       " 'trafficSource/adwordsClickInfo/slot',\n",
       " 'trafficSource/campaign',\n",
       " 'trafficSource/keyword',\n",
       " 'trafficSource/medium',\n",
       " 'trafficSource/referralPath',\n",
       " 'trafficSource/source']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep an unencoded copy for visualization\n",
    "unencoded_train = train.copy(deep=True)\n",
    "\n",
    "categories = list(train.select_dtypes(include='object').columns)\n",
    "categories.remove('fullVisitorId')\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: Contains \"Google\"\n",
    "* For the following columns, many rows with non-zero revenue have a string containing some variation of \"Google\"\n",
    "    * trafficSource/keyword\n",
    "    * trafficSource/adContent\n",
    "    * trafficSource/adwordsClickInfo/adNetworkType\n",
    "    * trafficSource/source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "google_cols = ['trafficSource/keyword', \n",
    "               'trafficSource/adContent', \n",
    "               'trafficSource/adwordsClickInfo/adNetworkType', \n",
    "               'trafficSource/source']\n",
    "\n",
    "def contains_google(df):\n",
    "    for i in google_cols:\n",
    "        if i not in df.columns:\n",
    "            continue\n",
    "        df['{0}/contains_google'.format(i)] =\\\n",
    "        df[i].apply(lambda x: bool(re.search('google', x, re.IGNORECASE)))\n",
    "        df.drop(columns=[i], inplace=True)\n",
    "    return df\n",
    "\n",
    "#\n",
    "train = contains_google(train)\n",
    "test  = contains_google(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "* Removing some columns for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['sessionId',\n",
    "           'trafficSource/adwordsClickInfo/gclId',\n",
    "           'trafficSource/adwordsClickInfo/page',\n",
    "           'trafficSource/campaign',\n",
    "           'trafficSource/referralPath',\n",
    "           'geoNetwork/networkDomain']\n",
    "\n",
    "def drop_columns(df):\n",
    "    for c in to_drop:\n",
    "        if c in df.columns:\n",
    "            df.drop(columns=[c], inplace=True)\n",
    "    return df\n",
    "        \n",
    "#\n",
    "train = drop_columns(train)\n",
    "test  = drop_columns(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['channelGrouping',\n",
       " 'device/browser',\n",
       " 'device/deviceCategory',\n",
       " 'device/operatingSystem',\n",
       " 'geoNetwork/city',\n",
       " 'geoNetwork/continent',\n",
       " 'geoNetwork/country',\n",
       " 'geoNetwork/metro',\n",
       " 'geoNetwork/region',\n",
       " 'geoNetwork/subContinent',\n",
       " 'trafficSource/adwordsClickInfo/slot',\n",
       " 'trafficSource/medium']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = list(train.select_dtypes(include='object').columns)\n",
    "categories.remove('fullVisitorId')\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(df):\n",
    "    for i in categories:\n",
    "        if i not in df.columns:\n",
    "            continue\n",
    "        value_counts = df[i].value_counts()\n",
    "        if len(value_counts) > 4:\n",
    "            bound = value_counts[3]\n",
    "            bucket = value_counts[value_counts <= bound].index\n",
    "            if len(bucket) >= 1:\n",
    "                df[i] = df[i].replace(bucket, 'bucket')\n",
    "    df = pd.get_dummies(df, columns=categories)\n",
    "    return df\n",
    "\n",
    "#\n",
    "train = one_hot(train)\n",
    "test  = one_hot(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "* Target specified as ln(total transaction revenue + 1)\n",
    "    * Need to convert transactionRevenue column to accomodate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import log1p\n",
    "\n",
    "# to make the line more readable\n",
    "i = 'totals/transactionRevenue'\n",
    "\n",
    "train[i] = train[i].apply(lambda revenue: log1p(revenue))\n",
    "unencoded_train[i] = unencoded_train[i].apply(lambda revenue: log1p(revenue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External Dataset: OECD Consumer Confidence Index\n",
    "\n",
    "OECD - Total from Jan 2016 - Sep 2018\n",
    "\n",
    "https://data.oecd.org/leadind/consumer-confidence-index-cci.htm#indicator-chart\n",
    "\n",
    "\n",
    "* OECD (2018), Consumer confidence index (CCI) (indicator). doi: 10.1787/46434d78-en (Accessed on 11 October 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cci(df):\n",
    "    cci = pd.read_csv('./all/oecd_total_cci.csv', index_col=0)\n",
    "    cci_dict = cci.to_dict()['Value']\n",
    "    df['year-month']  = df['year'].astype(str) + '-' + df['month'].astype(str)\n",
    "    \n",
    "    df['cci'] = df['year-month'].map(cci_dict)\n",
    "    df['cci'].fillna(df['cci'].median(), inplace=True)\n",
    "    \n",
    "    df.drop(columns=['year-month'], inplace=True)\n",
    "    return df\n",
    "\n",
    "train = add_cci(train)\n",
    "test  = add_cci(test)\n",
    "unencoded_train = add_cci(unencoded_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove differences in columns from training set\n",
    "* Only column difference should be totals/transactionRevenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = train.columns\n",
    "test_columns  = test.columns\n",
    "in_both = list(set(train_columns) & set(test_columns))\n",
    "\n",
    "train_columns = in_both\n",
    "test_columns  = in_both[:]\n",
    "train_columns.append('totals/transactionRevenue')\n",
    "\n",
    "train = train[train_columns]\n",
    "test  = test[test_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Preprocessed DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('./all/p_train.csv', index=False)\n",
    "test.to_csv('./all/p_test.csv', index=False)\n",
    "unencoded_train.to_csv('./all/unencoded_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "# Load Preprocessed DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "id_to_str = {'fullVisitorId': str}\n",
    "\n",
    "train = pd.read_csv('./all/p_train.csv', dtype=id_to_str)\n",
    "test  = pd.read_csv('./all/p_test.csv', dtype=id_to_str)\n",
    "unencoded_train = pd.read_csv('./all/unencoded_train.csv', dtype=id_to_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cats = unencoded_train.select_dtypes(exclude='object')\n",
    "\n",
    "i = 'totals/transactionRevenue'\n",
    "columns = list(no_cats.columns)\n",
    "columns.remove(i); columns.append(i)\n",
    "\n",
    "no_cats = no_cats[columns]\n",
    "\n",
    "no_cats_corr = no_cats.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Correlation Matrix (Non-Categorical Variables)', fontsize=15)\n",
    "sns.heatmap(no_cats_corr, cmap='coolwarm', annot=True, vmin=-1, vmax=1, \n",
    "            cbar_kws=dict(ticks=list(np.arange(-1.0, 1.1, 0.25))), fmt='.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cats.corr()['totals/transactionRevenue'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### The majority of paying customers will view the site under 30 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_tr = train[train['totals/transactionRevenue'] > 0]\n",
    "p_99 = np.percentile(pv_tr['totals/pageviews'].sort_values(), 99)\n",
    "pv_tr = pv_tr[pv_tr['totals/pageviews'] < p_99]\n",
    "\n",
    "x_values = pv_tr['totals/pageviews']\n",
    "y_values = pv_tr['totals/transactionRevenue']\n",
    "\n",
    "xy = np.vstack([x_values, y_values]); \n",
    "density = gaussian_kde(xy)(xy)\n",
    "\n",
    "plt.figure(figsize=(12, 10)); plt.title('Page Views of Paying Customers', fontsize=20)\n",
    "plt.xticks(np.arange(0, x_values.max(), step=5)); plt.yticks(np.arange(0, y_values.max(), step=1))\n",
    "plt.xlabel('Page Views', fontsize=15); plt.ylabel('Log Transaction Revenue', fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.scatter(x_values, y_values, alpha=1, c=density, cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Referalls bring in the most page views and the most revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser_rev = unencoded_train[['totals/transactionRevenue', 'channelGrouping']]\n",
    "#browser_rev = browser_rev[browser_rev['totals/transactionRevenue'] > 0]\n",
    "browser_rev = browser_rev.groupby('channelGrouping').mean()\n",
    "browser_rev = browser_rev.sort_values(by='totals/transactionRevenue', ascending=False)\n",
    "x = browser_rev.index\n",
    "y = browser_rev['totals/transactionRevenue']\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x, y).set_title('A')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_revenue = train[['totals/transactionRevenue', 'device/isMobile']]\n",
    "mobile_revenue = mobile_revenue.groupby('device/isMobile').sum()\n",
    "x = mobile_revenue.index\n",
    "y = mobile_revenue['totals/transactionRevenue']\n",
    "sns.barplot(x, y).set_title('A')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unencoded_train['month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unencoded_train['channelGrouping'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "https://support.google.com/analytics/answer/3297892?hl=en&ref_topic=6010089"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = unencoded_train[['channelGrouping', 'totals/transactionRevenue', 'month']]\n",
    "\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.xticks(np.arange(0, 12+1, step=1))\n",
    "channels = channels.sort_values(by='month')\n",
    "\n",
    "sns.set(style=\"ticks\", rc={\"lines.linewidth\": 6})\n",
    "sns.lineplot('month', 'totals/transactionRevenue', data=channels, err_style=None, estimator='mean', palette=\"colorblind\",  hue='channelGrouping')\n",
    "plt.title('Mean Revenue By Month', fontsize=25)\n",
    "plt.xlabel('Month', fontsize=20); \n",
    "plt.ylabel('Log Transaction Revenue', fontsize=20)\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=1, frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = unencoded_train[['channelGrouping', 'totals/pageviews', 'month']]\n",
    "channels = channels[channels['channelGrouping'] != '(Other)']\n",
    "\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.xticks(np.arange(0, 12+1, step=1))\n",
    "channels = channels.sort_values(by='month')\n",
    "\n",
    "sns.set(style=\"ticks\", rc={\"lines.linewidth\": 6})\n",
    "sns.lineplot('month', 'totals/pageviews', data=channels, err_style=None,  hue='channelGrouping')\n",
    "plt.title('Page Views By Month and Channel Grouping', fontsize=20)\n",
    "plt.xlabel('Month', fontsize=15); \n",
    "plt.ylabel('Page Views', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tt_split(df):\n",
    "    X = df.drop(columns=['totals/transactionRevenue', 'fullVisitorId'])\n",
    "    y = df['totals/transactionRevenue']\n",
    "    \n",
    "    return train_test_split(X, y, test_size = 0.1, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt\n",
    "from numpy import clip\n",
    "\n",
    "def train_lr(df):\n",
    "    X_train, X_test, y_train, y_test = get_tt_split(df)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    print('Training model: {0}...\\n'.format('lr'))\n",
    "    model.fit(X_train, y_train)\n",
    "    test_predictions = model.predict(X_test)\n",
    "    test_predictions = clip(test_predictions, a_min=0, a_max=None)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, test_predictions)\n",
    "    rmse = sqrt(mse)\n",
    "    \n",
    "    print('=====')\n",
    "    print('RMSE:', rmse)\n",
    "    print('=====\\n\\n==========')\n",
    "    print('INTERCEPT:', model.intercept_)\n",
    "    print('==========\\n\\n==========================')\n",
    "    print('COEFFICIENTS (decreasing):')\n",
    "    print('==========================')\n",
    "    coefficients = list(zip(X_test.columns, model.coef_))\n",
    "    coefficients.sort(key = lambda c: c[1])\n",
    "    for i in coefficients[::-1]:\n",
    "        print('{0}:\\n\\t{1}\\n'.format(i[0], i[1]))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: lr...\n",
      "\n",
      "=====\n",
      "RMSE: 1.809177127724782\n",
      "=====\n",
      "\n",
      "==========\n",
      "INTERCEPT: -5777.532793273914\n",
      "==========\n",
      "\n",
      "==========================\n",
      "COEFFICIENTS (decreasing):\n",
      "==========================\n",
      "year:\n",
      "\t2.9235173845031905\n",
      "\n",
      "totals/bounces:\n",
      "\t0.35194058116154275\n",
      "\n",
      "totals/pageviews:\n",
      "\t0.26287769645484527\n",
      "\n",
      "month:\n",
      "\t0.24931753904567697\n",
      "\n",
      "geoNetwork/country_United States:\n",
      "\t0.2070333798108353\n",
      "\n",
      "trafficSource/medium_referral:\n",
      "\t0.19246745898774345\n",
      "\n",
      "geoNetwork/metro_bucket:\n",
      "\t0.12995820865938498\n",
      "\n",
      "trafficSource/adwordsClickInfo/adNetworkType/contains_google:\n",
      "\t0.1194052442394892\n",
      "\n",
      "device/operatingSystem_Macintosh:\n",
      "\t0.09898160981322648\n",
      "\n",
      "cci:\n",
      "\t0.09117718132140583\n",
      "\n",
      "device/deviceCategory_desktop:\n",
      "\t0.06827551766679271\n",
      "\n",
      "channelGrouping_bucket:\n",
      "\t0.06517463559935287\n",
      "\n",
      "geoNetwork/city_bucket:\n",
      "\t0.05476007742616696\n",
      "\n",
      "trafficSource/source/contains_google:\n",
      "\t0.05076248709913875\n",
      "\n",
      "trafficSource/adwordsClickInfo/slot_RHS:\n",
      "\t0.03689108725109238\n",
      "\n",
      "geoNetwork/continent_bucket:\n",
      "\t0.032897416992357535\n",
      "\n",
      "device/browser_bucket:\n",
      "\t0.029479240153955814\n",
      "\n",
      "trafficSource/keyword/contains_google:\n",
      "\t0.02656662979871958\n",
      "\n",
      "geoNetwork/city_(not set):\n",
      "\t0.02339704744370887\n",
      "\n",
      "geoNetwork/subContinent_Southern Asia:\n",
      "\t0.022183142993740468\n",
      "\n",
      "channelGrouping_Direct:\n",
      "\t0.019898276666549697\n",
      "\n",
      "trafficSource/medium_(none):\n",
      "\t0.01989827666653618\n",
      "\n",
      "device/isMobile:\n",
      "\t0.019257025283516208\n",
      "\n",
      "device/browser_Chrome:\n",
      "\t0.016166576040113585\n",
      "\n",
      "day:\n",
      "\t0.007932886941586725\n",
      "\n",
      "device/browser_Firefox:\n",
      "\t0.006533034053578256\n",
      "\n",
      "geoNetwork/continent_Europe:\n",
      "\t0.004955876702124638\n",
      "\n",
      "hour:\n",
      "\t0.00217501866343512\n",
      "\n",
      "geoNetwork/region_not available in demo dataset:\n",
      "\t0.0015852780813615688\n",
      "\n",
      "geoNetwork/city_not available in demo dataset:\n",
      "\t0.0015852780813607734\n",
      "\n",
      "geoNetwork/metro_not available in demo dataset:\n",
      "\t0.001585278081359397\n",
      "\n",
      "geoNetwork/region_bucket:\n",
      "\t0.00032073924658686855\n",
      "\n",
      "visitId:\n",
      "\t-8.701580389569585e-08\n",
      "\n",
      "device/operatingSystem_bucket:\n",
      "\t-0.0022983877344170183\n",
      "\n",
      "visitNumber:\n",
      "\t-0.0024569541315869123\n",
      "\n",
      "geoNetwork/continent_Americas:\n",
      "\t-0.017566389755427934\n",
      "\n",
      "device/deviceCategory_mobile:\n",
      "\t-0.01920659021839484\n",
      "\n",
      "geoNetwork/continent_Asia:\n",
      "\t-0.020286904139495243\n",
      "\n",
      "trafficSource/adContent/contains_google:\n",
      "\t-0.03537063691383169\n",
      "\n",
      "trafficSource/adwordsClickInfo/slot_Top:\n",
      "\t-0.03689108723218995\n",
      "\n",
      "trafficSource/medium_organic:\n",
      "\t-0.03849995791474549\n",
      "\n",
      "channelGrouping_Organic Search:\n",
      "\t-0.03849995888933925\n",
      "\n",
      "device/operatingSystem_Windows:\n",
      "\t-0.04242383013140086\n",
      "\n",
      "channelGrouping_Social:\n",
      "\t-0.046572953397375313\n",
      "\n",
      "device/deviceCategory_tablet:\n",
      "\t-0.049068927448381684\n",
      "\n",
      "device/browser_Safari:\n",
      "\t-0.05217884979667283\n",
      "\n",
      "device/operatingSystem_Android:\n",
      "\t-0.054259392084984245\n",
      "\n",
      "geoNetwork/subContinent_bucket:\n",
      "\t-0.0545847789230983\n",
      "\n",
      "geoNetwork/metro_San Francisco-Oakland-San Jose CA:\n",
      "\t-0.055112902800555454\n",
      "\n",
      "geoNetwork/country_India:\n",
      "\t-0.062047767502791465\n",
      "\n",
      "geoNetwork/country_bucket:\n",
      "\t-0.06312299446672663\n",
      "\n",
      "geoNetwork/metro_(not set):\n",
      "\t-0.07643058426273254\n",
      "\n",
      "geoNetwork/city_Mountain View:\n",
      "\t-0.07974240195738197\n",
      "\n",
      "geoNetwork/country_United Kingdom:\n",
      "\t-0.0818626178845954\n",
      "\n",
      "geoNetwork/region_California:\n",
      "\t-0.09899154177599122\n",
      "\n",
      "totals/hits:\n",
      "\t-0.10697925326972949\n",
      "\n",
      "geoNetwork/subContinent_Northern America:\n",
      "\t-0.1408418281892398\n",
      "\n",
      "trafficSource/medium_bucket:\n",
      "\t-0.17386577961418237\n",
      "\n",
      "totals/newVisits:\n",
      "\t-0.2498743226426621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model = train_lr(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import DMatrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt\n",
    "from numpy import clip\n",
    "\n",
    "def train_xgb(df):\n",
    "    X_train, X_test, y_train, y_test = get_tt_split(df)\n",
    "    \n",
    "    print('Training model: {0}...'.format('xgb'))\n",
    "    model = xgb.train({}, DMatrix(X_train, y_train))\n",
    "    test_predictions = model.predict(DMatrix(X_test))\n",
    "    test_predictions = clip(test_predictions, a_min=0, a_max=None)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, test_predictions)\n",
    "    rmse = sqrt(mse)\n",
    "    \n",
    "    print('=====')\n",
    "    print('RMSE:', rmse)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: xgb...\n",
      "=====\n",
      "RMSE: 1.6536570893039457\n"
     ]
    }
   ],
   "source": [
    "xgb_model = train_xgb(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Specify model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = 'xgb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: xgb...\n",
      "=====\n",
      "RMSE: 1.6516302891477297\n"
     ]
    }
   ],
   "source": [
    "X_test = test.drop(columns=['fullVisitorId'])\n",
    "\n",
    "if selected_model == 'lr':\n",
    "    model = train_lr(train)\n",
    "elif selected_model == 'xgb':\n",
    "    model = train_xgb(train)\n",
    "    X_test = DMatrix(X_test)\n",
    "\n",
    "real_predictions = model.predict(X_test)\n",
    "real_predictions = clip(real_predictions, a_min=0, a_max=None)\n",
    "\n",
    "real_df = test['fullVisitorId'].to_frame()\n",
    "real_df['PredictedLogRevenue'] = real_predictions\n",
    "real_df['fullVisitorId'] = real_df['fullVisitorId'].astype('str')\n",
    "real_df = real_df.groupby('fullVisitorId').sum()\n",
    "real_df.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
